
**DAY 1:**
I have started with pandas  which is a python library for data  analysis.<br />

[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6427904572823560192)


**DAY 2:**
I brushed up my knowledge on numpy  and practiced a few programs on HackerRank.<br />

[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6428299354876014592)


**DAY 3:**
 I started browsing the basic difference in pandas python library.<br />

 [Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6428684475894456320)
 
 
**DAY 4, 5:**
The tasks I have accomplished are understanding :
1. cost functions
2. gradient descent
3. linear regression from scratch<br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/LinearRegression.jpg)<br />

[Linkedin post]( https://www.linkedin.com/feed/update/urn:li:activity:6429363029376360448)
 
 
 **DAY 6,7:**
By the end of #week1ofmlcode in 100 days of ml coding challenge,  I thought of taking up a course on Coursera -"Introduction to Data Science in Python" which would help me to emulate the best and I successfully completed the course which helped me in understanding data manipulation and cleaning techniques using the popular python pandas data science library.
[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6430117806284599296) <br />

[code](https://lnkd.in/fR9hbRm) is available.


**DAY 8,9:**
I have learned efficient ways to use the Mathplotlib which is a plotting library for the Python programming language and its numerical mathematics extension NumPy.<br />

[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6430850443429154816)


**DAY 10,11:**
LOGISTIC REGRESSION
[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6432501259634343936) <br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/LogisticRegression.jpg)<br />

[code]( https://lnkd.in/fhy7TW3) is available.


**DAY 12**:
understood the following concepts:
fixing missingdata using 'Imputer', categorical data using 'LabelEncoder' and dummy Encoding using 'OneHotEncoder' and finally splitting dataset into 'testset' and 'trainset' using train_test_split from sklearn libraries.


**DAY 13:**
gone through a few research papers which helped in understanding the real world applications of machine learning.
[ youtube](https://www.youtube.com/watch?v=SHTOI0KtZnU)


**DAY 14:**
DECISION TREE: Basic concepts and a few terminologies like prunning, information gain, gini impurity etc.
[link ](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)to reference.


**DAY 15:**
Decision tree implementation from scratch using python.
[youtube](https://www.youtube.com/watch?v=qDcl-FRnwSU&t=2440s)


**DAY 16:**
Implementation of decision tree using sklearn.
Detailed explanation on [linkedin]( https://www.linkedin.com/feed/update/urn:li:activity:6435936765810446336)<br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/DecisionTree.jpg)<br />

 [code](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/decision_tree1.ipynb)


**DAY 17:**
TOPIC: Probability
UNDERSTANDING: In machine learning, the concept of probability plays an important role. For example, we ask our machine learning algorithm how likely our result is. Thus, after knowing the importance I started a playlist of Prof. Joe Biltzstein from Harvard University.
[Source]( https://www.youtube.com/watch?v=KbB0FjPg0mw&list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)


**DAY 18:**
Watched a few videos and read some articles on ml.
[Source](https://docs.microsoft.com/en-us/azure/machine-learning/studio/data-science-for-beginners-the-5-questions-data-science-answers)<br />

[Youtube ](https://www.youtube.com/watch?v=LQEyK4POowk)

**DAY 19-23:**
Proper understanding on probability.Wrote my first blog article [INTUITIONS ON PROBABILITY](http://thrivetoknow.blogspot.com/2018/08/intuitions-on-probability.html)


**DAY 24-26:**
Participated in my first real-world [competition](https://www.machinehack.com/course/predicting-house-prices-in-bengaluru/?renew)

**DAY 27,28:**
Naive Bayes Classifier:
This algorithm is mostly used in text classification/ Spam Filtering/ Sentiment Analysis/Recommendation System and with problems having multiple classes.Knew 3 different popular [Naive Bayes classifiers](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
).


**DAY 29:**
Naive Bayes
[Infografic](https://www.linkedin.com/feed/update/urn:li:activity:6441790742829588480) <br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/NaiveBayes1.jpg)


**DAY 30:**
[Naive bayes](https://github.com/neha-duggirala/100DaysOfMLCode/tree/master/Naive-bayes) code from scratch using python
![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/NaiveBayes2.jpg)


**DAY 30-34:**
[SVM](https://eduvatecom.wordpress.com/2018/09/16/large-margin-classifier-svm/) article.


**DAY 35-37:**
Linear and non Linear classification using SVM:<br/>
Based on the dataset, if it is linearly separable  LinearSVM can be used or
else  kernel trick is used to project the data into a high-dimensional space before attempting to find a hyperplane.
<br/>
Spam classification:<br/>
Many email services today provide spam filters that are able to classify emails 
into spam and non-spam email with high accuracy.SVMs are used to build own spam filter.<br/>
![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/svm_infographic.png)

[Github code](https://github.com/neha-duggirala/100DaysOfMLCode/tree/master/SupportVectorMachine)


**DAY 38-40:**</br>
Ensemble learning helps improve machine learning results by combining several models. This approach allows the production of better predictive performance compared to a single model.</br>
references:https://blog.statsbot.co/ensemble-learning-d1dcd548e936
[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6448941159027965952/)
<br/>![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/Ensemble_Learning.png)



**DAY 41:**</br>
Participated in an [online hackathon](https://www.techgig.com/hackathon/question/OGJobFRZZWJSVWlITTk1cnpXQWIraG1VaE5CMjdWWXpTU3JDYkpNRVI3RT0=/1)
on data science 


**DAY 42:**</br>
By using Sklearn libraries [implemented](https://github.com/neha-duggirala/100DaysOfMLCode/tree/master/Ensemble%20Learning)
</br>Useful [resources](https://www.linkedin.com/feed/update/urn:li:activity:6449671205602590720)


**DAY 43,44:**</br>
Flask is the best choice for all the web programmers, to start from the scratch and for building minimalistic web applications. One more advantage of using Flask is you can integrate machine learning algorithms(Python Based) within the functions with ease which makes your applications more intelligent and cognitive.

Here are few websites models you can build with Flask:

Blog Applications, Chat Applications, Data Visualisation, Dashboards, REST Applications, Admin Pages, Email-Services.
so I did a small Project on building a database for an art gallery
</br>![My work](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/Art%20Gallery.jpg)



**DAY 45,46:**</br>
As teaching gives a better learning, I've prepared and given a [seminar](https://www.linkedin.com/feed/update/urn:li:activity:6451223047323127808) at Gandhi Institute of Technology & Management (GITAM) University, Visakhapatnam today. I've introduced the standard ML problem types (classification and regression) and discuss prediction functions, feature extraction, learning algorithms, performance evaluation, cross-validation, sample bias, nonstationarity, overfitting, and hyperparameter tuning.


**DAY 47-50:**</br>
Data Preprocessing:</br>
https://www.youtube.com/watch?v=0xVqLJe9_CY&list=PL2-dafEMk2A64Er6yZHw1CJoFWQqYxj4B</br>
https://www.analyticsvidhya.com/blog/2016/07/practical-guide-data-preprocessing-python-scikit-learn/</br>
https://www.kdnuggets.com/2017/06/7-steps-mastering-data-preparation-python.html</br>


**DAY 51:**</br>
Introduction to Supervized learning</br>
Clustering Algorithms (K-means): k-means clustering is a method of vector quantization, originally from signal processing, that is popular for cluster analysis in data mining. It has two main steps.</br> STEP ONE: Cluster assignment</br> STEP TWO: Move the centroid
